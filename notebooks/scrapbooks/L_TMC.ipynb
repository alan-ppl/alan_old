{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch as t\n",
    "\n",
    "from torch.distributions import Normal, Categorical\n",
    "from torch.distributions import MultivariateNormal as MVN\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P(nn.Module):\n",
    "    def __init__(self, Pw, PzGw, PxGz):\n",
    "        super().__init__()\n",
    "        self.Pw = Pw\n",
    "        self.PzGw = PzGw\n",
    "        self.PxGz = PxGz\n",
    "\n",
    "    def sample(self, N):\n",
    "        w = self.Pw().sample()\n",
    "        z = self.PzGw(w).sample(sample_shape=t.Size([N]))\n",
    "        x = self.PxGz(z).sample()\n",
    "        return (x, (w.unsqueeze(-1), z))\n",
    "\n",
    "    def log_prob(self, xwz):\n",
    "        x, (w, z) = xwz\n",
    "        logPw   = self.Pw().log_prob(w)\n",
    "        logPzGw = self.PzGw(w).log_prob(z)\n",
    "        logPxGz = self.PxGz(z).log_prob(x)\n",
    "        return logPw.sum(-1) + logPzGw.sum(-1) + logPxGz.sum(-1)\n",
    "\n",
    "\n",
    "class Q(nn.Module):\n",
    "    def __init__(self, Qw, Qz):\n",
    "        super().__init__()\n",
    "        self.Qw = Qw\n",
    "        self.Qz = Qz\n",
    "\n",
    "    def sample(self, N, sample_shape=t.Size([])):\n",
    "        w = self.Qw().sample(sample_shape=sample_shape)\n",
    "        z = self.Qz().sample(sample_shape=t.Size([*sample_shape, N]))\n",
    "        return (w.unsqueeze(-1), z)\n",
    "\n",
    "    def log_prob(self, wz):\n",
    "        w, z = wz\n",
    "        logQw = self.Qw().log_prob(w)\n",
    "        logQz = self.Qz().log_prob(z)\n",
    "        return logQw.sum(-1) + logQz.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pqx(N, sw, sz, sx):\n",
    "    w = ParamNormal((), scale=sw)\n",
    "    zw = LinearNormal((), scale=sz)\n",
    "    xz = LinearNormal((), scale=sx)\n",
    "    p = P(w, zw, xz)\n",
    "    x, _ = p.sample(N)\n",
    "\n",
    "    w_q = ParamNormal((), scale=sw)\n",
    "    zw_q = ParamNormal((), scale=math.sqrt(sw**2+sz**2))\n",
    "    q = Q(w_q, zw_q)\n",
    "    #(w, z) = q.sample(t.Size([3]))\n",
    "    return (p, q, x)\n",
    "\n",
    "    \n",
    "class ParamNormal(nn.Module):\n",
    "    def __init__(self, sample_shape, scale=1.):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Parameter(t.zeros(sample_shape))\n",
    "        self.log_scale = nn.Parameter(math.log(scale)*t.ones(sample_shape))\n",
    "\n",
    "    def forward(self):\n",
    "        return Normal(self.loc, self.log_scale.exp())\n",
    "\n",
    "    \n",
    "\n",
    "class LinearNormal(nn.Module):\n",
    "    def __init__(self, sample_shape=t.Size([]), scale=1.):\n",
    "        super().__init__()\n",
    "        self.log_scale = nn.Parameter(math.log(scale)*t.ones(sample_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        return Normal(input, self.log_scale.exp())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-132.7456)\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "sw = 1.\n",
    "sz = 1.\n",
    "sx = 0.1\n",
    "p, q, x = pqx(N, sw=sw, sz=sz, sx=sx)\n",
    "var = sw**2 * t.ones(N, N) + (sz**2+sx**2)*t.eye(N)\n",
    "m = MVN(t.zeros(N), var)\n",
    "\n",
    "print(m.log_prob(x.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Usual single/multi-sample VAE\n",
    "    \"\"\"\n",
    "    def __init__(self, p, q, K):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        self.K = K\n",
    "\n",
    "    def forward(self, x):\n",
    "        wz = self.q.sample(x.size(0), sample_shape=t.Size([self.K]))\n",
    "        elbo = self.p.log_prob((x, wz)) - self.q.log_prob(wz)\n",
    "        lme = logmeanexp(elbo)\n",
    "        return lme\n",
    "\n",
    "    def train(self, x):\n",
    "        opt = t.optim.Adam(q.parameters())\n",
    "        for i in range(100):\n",
    "            #opt.zero_grad()\n",
    "            obj = self(x)\n",
    "            #(-obj).backward()\n",
    "            #opt.step()\n",
    "            print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMC(nn.Module):\n",
    "    def __init__(self, p, q, Kw, Kz=None):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        if Kz is None:\n",
    "            Kz = Kw\n",
    "        self.Kw = Kw\n",
    "        self.Kz = Kz\n",
    "\n",
    "    def train(self, x):\n",
    "        opt = t.optim.Adam(q.parameters())\n",
    "        for i in range(100):\n",
    "            #opt.zero_grad()\n",
    "            obj = self(x)\n",
    "            #(-obj).backward()\n",
    "            #opt.step()\n",
    "            print(obj)\n",
    "\n",
    "class TMC(TMC):\n",
    "    def forward(self, x):\n",
    "        w  = self.q.Qw().sample(sample_shape=t.Size([self.Kw, 1, 1]))\n",
    "        z  = self.q.Qz().sample(sample_shape=t.Size([self.Kz, x.size(0)]))\n",
    "        fw = self.p.Pw().log_prob(w) - self.q.Qw().log_prob(w)\n",
    "        fz = self.p.PzGw(w).log_prob(z) - self.q.Qz().log_prob(z)\n",
    "        fx = self.p.PxGz(z).log_prob(x)\n",
    "        f_int_z = logmeanexp(fz + fx, -2)\n",
    "        f_int_z = f_int_z.sum(-1) + fw.view(-1)\n",
    "        f_int_w = logmeanexp(f_int_z)\n",
    "\n",
    "        return f_int_w#.sum(0)\n",
    "\n",
    "class TMC_Shared(TMC):\n",
    "    def forward(self, x):\n",
    "        w  = self.q.Qw().sample(sample_shape=t.Size([self.Kw]))\n",
    "        z  = self.q.Qz().sample(sample_shape=t.Size([self.Kz]))\n",
    "        fw = self.p.Pw().log_prob(w) - self.q.Qw().log_prob(w)\n",
    "\n",
    "        fz = self.p.PzGw(w.unsqueeze(1)).log_prob(z) - self.q.Qz().log_prob(z)\n",
    "        fx = self.p.PxGz(z.unsqueeze(1)).log_prob(x)\n",
    "        #f_int_z = logmeanexp(fz + fx, -2)\n",
    "        f_int_z = logmmmeanexp(fz, fx)\n",
    "        f_int_z = f_int_z.sum(-1) + fw.view(-1)\n",
    "        f_int_w = logmeanexp(f_int_z)\n",
    "\n",
    "        return f_int_w#.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def logmeanexp(x, dim=0):\n",
    "    max = x.max(dim=dim, keepdim=True)[0]\n",
    "    return ((x-max).exp().mean(dim, keepdim=True).log()+max).squeeze(dim)\n",
    "\n",
    "def logsumexp(x, dim=0):\n",
    "    max = x.max(dim=dim, keepdim=True)[0]\n",
    "    return ((x-max).exp().sum(dim, keepdim=True).log()+max).squeeze(dim)\n",
    "\n",
    "def logmmmeanexp(X, Y):\n",
    "    x = X.max(dim=1, keepdim=True)[0]\n",
    "    y = Y.max(dim=0, keepdim=True)[0]\n",
    "    X = X - x\n",
    "    Y = Y - y\n",
    "    return x + y + t.mm(X.exp(), Y.exp()).log() - t.log(t.ones((), device=x.device)*X.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-133.81053\n"
     ]
    }
   ],
   "source": [
    "iters = 10\n",
    "\n",
    "tmc = TMC(p, q, 501, 502)\n",
    "tmcs = []\n",
    "\n",
    "for i in range(iters):\n",
    "    t.manual_seed(i)\n",
    "    res = tmc(x)\n",
    "    tmcs.append(res.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "tmcs = np.array(tmcs)\n",
    "print(tmcs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# https://pyro.ai/examples/vae.html\n",
    "# https://pyro.ai/examples/dmm.html\n",
    "def model():\n",
    "    z_prev = self.z_0\n",
    "\n",
    "    # sample the latents z and observed x's one time step at a time\n",
    "    for t in range(1, T_max + 1):\n",
    "        # the next two lines of code sample z_t ~ p(z_t | z_{t-1}).\n",
    "        # first compute the parameters of the diagonal gaussian\n",
    "        # distribution p(z_t | z_{t-1})\n",
    "        z_loc, z_scale = self.trans(z_prev)\n",
    "        # then sample z_t according to dist.Normal(z_loc, z_scale)\n",
    "        normal = Normal(z_loc, z_scale)\n",
    "        z_t = normal.rsample()\n",
    "\n",
    "        # compute the probabilities that parameterize the bernoulli likelihood\n",
    "        emission_probs_t = self.emitter(z_t)\n",
    "        # the next statement instructs pyro to observe x_t according to the\n",
    "        # bernoulli distribution p(x_t|z_t)\n",
    "        pyro.sample(\"obs_x_%d\" % t,\n",
    "                    dist.Bernoulli(emission_probs_t),\n",
    "                    obs=mini_batch[:, t - 1, :])\n",
    "        # the latent sampled at this time step will be conditioned upon\n",
    "        # in the next time step so keep track of it\n",
    "        z_prev = z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
